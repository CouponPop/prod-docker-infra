# Logstash CloudWatch Input Configuration (logstash.conf)

# Logstash가 CloudWatch Input 플러그인을 설치하도록 startup 명령에 추가해야 합니다.
# Logstash Dockerfile이 없다면, docker-compose command나 custom Dockerfile에서 처리해야 합니다.

input {
  # [!!] CRITICAL FIX: Beats Input을 CloudWatch Input으로 교체합니다.
  cloudwatch {
    # Store Service의 고유 로그 그룹 이름을 구독합니다.
    log_group_name_prefix => "/ecs/couponpop-store-service-task-definition"
    region => "ap-northeast-2"

    # Logstash가 CloudWatch API를 호출하여 로그를 읽어오도록 설정합니다.
    use_actual_time => true
    start_position => "end" # Logstash 시작 시 최신 로그부터 읽기 시작
    interval => 30 # 30초마다 CloudWatch Logs에서 새 로그를 폴링
  }
}

filter {
  # Grok 필터: Java 로그 패턴에 맞춰 메시지를 파싱합니다.
  grok {
    match => { "message" => [
      "^%{TIMESTAMP_ISO8601:log_timestamp}\s+%{LOGLEVEL:level}\s+%{NUMBER:pid}\s+---\s+\[%{DATA:service_name}\]\s+\[%{DATA:thread_name}\]\s+%{JAVACLASS:logger_name}\s+:\s+%{GREEDYDATA:log_message}"
    ]}
  }

  # Grok 파싱 실패가 아닌 경우에만 시간 변환 및 필드 정리
  if ![tags] or ! ("_grokparsefailure" in [tags]) {

    date {
      match => [ "log_timestamp", "ISO8601" ]
      target => "@timestamp"
    }

    mutate {
      uppercase => [ "level" ]
      remove_field => [ "log_timestamp" ]
    }
  }
}

output {
  # Elasticsearch로 최종 데이터 전송
  elasticsearch {
    hosts => ["http://elastic:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
  }

  # 디버깅용 콘솔 출력 (Logstash 로그 확인 시 유용)
  stdout {
    codec => rubydebug
  }
}